## Reasoning on Arguments and Beliefs with Probabilistic Logic Programs
Thursday 8th December, 16:00 GMT

### Abstract

The goal of probabilistic logic programming (PLP) languages and systems is to offer a general framework to reason and learn in structured, uncertain domains. An example of such domains are probabilistic argumentation problems, which describe arguments and their relations under uncertainty. However, whether PLP systems can effectively model and reason over these problems is still an open question. In this talk I will discuss the relations between the semantics of PLP and the semantics of probabilistic argumentation frameworks. I will establish a connection by describing a novel mapping of probabilistic argument frameworks to probabilistic logic programs. By encoding the beliefs and relations of arguments in a PLP model, we can use on probabilistic argumentation problems the traditional reasoning and learning tools available in PLP frameworks, such as conditional queries, most probable explanation queries, and parameter learning. The last part of the talk will be dedicated to an overview of smProbLog, a novel PLP framework where these tools are available. 

[Explainable AI Seminars @ Imperial](xaiseminars.doc.ic.ac.uk)

*CLArg Group, Department of Computing, Imperial College London*

XAI has witnessed unprecedented growth in both academia and industry in recent years (alongside AI itself), given its crucial role in supporting human-AI partnerships whereby (potentially opaque) data-driven AI methods can be intelligibly and safely deployed by humans in a variety of settings, such as finance, healthcare and law. XAI is positioned at the intersection of AI, human-computer interaction, the social sciences (and in particular psychology) and applications.

Overall, XAI is increasingly part of all AI policies on ethics, trustworthiness and safety of AI. This seminar series focuses on all aspects of XAI, ranging from methods to applications. 